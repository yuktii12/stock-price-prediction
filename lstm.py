# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lJ1223O1WEnPvW8KUwlePXEnCgnfFRHw
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pandas_datareader as data

from pandas_datareader import data as pdr #import pandas datareader

import yfinance as yf # you will need to install it if haven't done it already

#override the data reader function

yf.pdr_override()

data = pdr.get_data_yahoo("AAPL", start="2010-01-01", end="2022-12-31") 
data.head()

data.tail()

data=data.reset_index()
data.head()

data=data.drop(['Date','Adj Close'],axis=1)
data.head()

plt.plot(data.Close)
#closing points

#ma=moving average
ma100=data.Close.rolling(100).mean()
ma100

plt.figure(figsize=(12,6))
plt.plot(data.Close)
plt.plot(ma100,'r')
#graph with 100 days moving average

#ma=moving average
ma200=data.Close.rolling(200).mean()
ma200

plt.figure(figsize=(12,6))
plt.plot(data.Close)
plt.plot(ma100,'r')
plt.plot(ma200,'g')
#graph with 200 days moving average

data.shape

#Splitting the data into training and testing
data_training=pd.DataFrame(data['Close'][0:int(len(data)*0.70)])
data_testing=pd.DataFrame(data['Close'][int(len(data)*0.70):int(len(data))])
print(data_training.shape)
print(data_testing.shape)
#70% data is traing data and 30% data is testing data

data_training.head()

data_testing.head()

#Scaling of the data between 0 and 1 
from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler(feature_range=(0,1))

data_training_array=scaler.fit_transform(data_training)
data_training_array

x_train=[]
y_train=[]

for i in range(100,data_training_array.shape[0]):
    x_train.append(data_training_array[i-100:i])
    y_train.append(data_training_array[i,0])
    
x_train,y_train=np.array(x_train),np.array(y_train)

x_train.shape
#ML Model

import tensorflow
from tensorflow import keras
from keras.layers import Dense,Dropout,LSTM
from keras.models import Sequential

model = Sequential()
model.add(LSTM(units=50,activation='relu',return_sequences= True, input_shape=(x_train.shape[1],1)))
model.add(Dropout(0.2))

model = Sequential()
model.add(LSTM(units=60,activation='relu',return_sequences= True))
model.add(Dropout(0.3))

model = Sequential()
model.add(LSTM(units=80,activation='relu',return_sequences= True))
model.add(Dropout(0.4))

model = Sequential()
model.add(LSTM(units=120,activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(units=1))

model.compile(optimizer='adam',loss='mean_squared_error')
model.fit(x_train,y_train,epochs=50)
#time series analysis

#now the model is trained so we will save this model for future use
model.save('keras_model.h5')

data_testing.head()

data_training.tail(100)

past_100_days=data_training.tail(100)
final_data=past_100_days.append(data_testing,ignore_index=True)
print(final_data)

final_data.head()

input_data=scaler.fit_transform(final_data)
input_data

input_data.shape

x_test=[]
y_test=[]
for i in range(100,input_data.shape[0]):
  x_test.append(input_data[i-100:i])
  y_test.append(input_data[i,0])

x_test,y_test=np.array(x_test),np.array(y_test)
print(x_test.shape)
print(y_test.shape)

#Make prediction
y_predicted=model.predict(x_test)

y_predicted.shape

y_test

y_predicted

#Again we have to scale down
scaler.scale_

scale_factor=1/0.02123255
y_predicted=y_predicted*scale_factor
y_test=y_test*scale_factor

plt.figure(figsize=(12,6))
plt.plot(y_test,'b',label='Original Price')
plt.plot(y_predicted,'r',label='Predicted Price')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

!pip install streamlit -q

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt
# import pandas_datareader as data
# from keras.models import load_model
# import streamlit as st
# 
# from pandas_datareader import data as pdr #import pandas datareader
# 
# import yfinance as yf # you will need to install it if haven't done it already
# 
# #override the data reader function
# 
# yf.pdr_override()
# 
# 
# st.title('Stock Trend Prediction')
# 
# 
# user_input=st.text_input('Enter Stock Ticker','AAPL')
# data = pdr.get_data_yahoo("AAPL", start="2010-01-01", end="2019-12-31") 
# 
# #Describing Data
# st.subheader('Data from 2010-2019')
# st.write(data.describe())
# 
# #visualizations
# st.subheader('Closing Price vs Time Chart')
# fig=plt.figure(figsize=(12,6))
# plt.plot(data.Close)
# st.pyplot(fig)
# 
# st.subheader('Closing Price Vs Time Chart with 100MA')
# ma100 = data.Close.rolling(100).mean()
# fig=plt.figure(figsize = (12,6))
# plt.plot(ma100)
# plt.plot(data.Close)
# st.pyplot(fig)
# 
# st.subheader('Closing Price Vs Time Chart with 100MA and 200MA')
# ma100 = data.Close.rolling(100).mean()
# ma200 = data.Close.rolling(200).mean()
# fig=plt.figure(figsize = (12,6))
# plt.plot(ma100, 'r')
# plt.plot(ma200, 'g')
# plt.plot(data.Close, 'b')
# st.pyplot(fig)
# 
# #Splitting the data into training and testing
# data_training=pd.DataFrame(data['Close'][0:int(len(data)*0.70)])
# data_testing=pd.DataFrame(data['Close'][int(len(data)*0.70):int(len(data))])
# 
# from sklearn.preprocessing import MinMaxScaler
# scaler=MinMaxScaler(feature_range=(0,1))
# 
# data_training_array =scaler.fit_transform(data_training)
# 
# #load model 
# model = load_model('keras_model.h5')
# 
# past_100_days=data_training.tail(100)
# final_data=past_100_days.append(data_testing,ignore_index=True)
# 
# input_data=scaler.fit_transform(final_data)
# 
# x_test=[]
# y_test=[]
# for i in range(100,input_data.shape[0]):
#   x_test.append(input_data[i-100:i])
#   y_test.append(input_data[i,0])
# 
# x_test,y_test=np.array(x_test),np.array(y_test)
# y_predicted=model.predict(x_test)
# 
# scaler =scaler.scale_
# scale_factor=1/scaler[0]
# y_predicted=y_predicted*scale_factor
# y_test=y_test*scale_factor
# 
# st.subheader('Predictions vs Original')
# fig2 =plt.figure(figsize=(12,6))
# plt.plot(y_test,'b',label='Original Price')
# plt.plot(y_predicted,'r',label='Predicted Price')
# plt.xlabel('Time')
# plt.ylabel('Price')
# plt.legend()
# st.pyplot(fig2)

!streamlit run app.py & npx localtunnel --port 8501